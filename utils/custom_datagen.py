import os

import numpy as np

from keras.preprocessing import image
import keras.backend as K

from geometry_processing.globals import VALID_DIR


# Helper to see if two images were generated by the same mesh.
def get_prefix(filename):
    return filename[:filename.index(".")]


class GroupedDatagen:
    def __init__(self, data_dir, shape=(224, 224, 3),
            preprocess=None, nb_class=10):
        self.data_dir = data_dir
        self.nb_class = nb_class
        self.preprocess = preprocess
        self.shape = shape
        self.class_mapping = dict()
        self.data_pairs = list()
        self.index = 0

        # Populate data pairs.
        self._setup()

    def _add_bin(self, classname, root, relative_paths):
        # Change to full paths.
        for j in range(len(relative_paths)):
            relative_paths[j] = os.path.join(root, relative_paths[j])
        self.data_pairs.append((relative_paths, classname))

    def _setup(self):
        # The files in this directory should be names of classes.
        for i, label in enumerate(sorted(os.listdir(self.data_dir))):
            self.class_mapping[label] = i

            # All the images associated with the class.
            for root, _, files in os.walk(os.path.join(self.data_dir, label)):
                if not files:
                    continue

                files.sort()
                current_bin = [files[0]]

                for j in range(1, len(files)):
                    # Generated from the same model.
                    if get_prefix(files[j]) == get_prefix(current_bin[-1]):
                        current_bin.append(files[j])
                    else:
                        self._add_bin(label, root, current_bin)
                        current_bin = [files[j]]

                # Don't forget the last bin.
                self._add_bin(label, root, current_bin)

    def _get_pairs(self, samples, shuffle):
        while True:
            if self.index == 0 and shuffle:
                np.random.shuffle(self.data_pairs)

            # All n samples of this batch belong to a single mesh.
            full_paths, label = self.data_pairs[self.index]

            assert samples <= len(full_paths)

            # Initialize batch.
            batch_x = np.zeros((samples,) + self.shape, dtype=K.floatx())
            batch_y = np.zeros((samples, self.nb_class), dtype=K.floatx())

            # Get some samples.
            for i, full_path in enumerate(full_paths):
                if i >= samples:
                    break

                img = image.load_img(full_path, target_size=self.shape)
                x = image.img_to_array(img)
                if self.preprocess:
                    x = self.preprocess(x)

                # Add sample to batch.
                batch_x[i] = x
                batch_y[i][self.class_mapping[label]] = 1.0

                # Mark this pair as used.
                self.index = (self.index + 1) % len(self.data_pairs)

            yield batch_x, batch_y

    def generate(self, samples=25, batch_size=64, shuffle=True):
        # Infinite generator.
        while True:
            x = np.zeros((batch_size, samples,) + self.shape, dtype=K.floatx())
            y = np.zeros((batch_size, samples, self.nb_class), dtype=K.floatx())

            for i, batch in enumerate(self._get_pairs(samples=samples,
                                                      shuffle=shuffle)):
                if i >= batch_size:
                    break

                batch_x, batch_y = batch
                x[i] = batch_x
                y[i] = batch_y

            yield x, y


class FilenameImageDatagen:
    def __init__(self, data_dir, shape=(224, 224, 3), preprocess=None):
        self.data_dir = data_dir
        self.preprocess = preprocess
        self.shape = shape

    def generate_single(self):
        # The files in this directory should be names of classes.
        for _, label in enumerate(sorted(os.listdir(self.data_dir))):
            # All the images associated with the class.
            for root, _, files in os.walk(os.path.join(self.data_dir, label)):
                for filename in sorted(files):
                    full_path = os.path.join(root, filename)

                    img = image.load_img(full_path, target_size=self.shape)
                    img = image.img_to_array(img)

                    if self.preprocess:
                        img = self.preprocess(img)

                    yield full_path, img

    def generate(self, batch_size=16):
        """Generates batchs of size batch_size except for the last batch."""
        paths = np.zeros((batch_size), dtype='object')
        images = np.zeros((batch_size,) + self.shape, dtype=K.floatx())

        next_spot = 0

        for _, path_image in enumerate(self.generate_single()):
            paths[next_spot] = path_image[0]
            images[next_spot] = path_image[1]
            next_spot += 1

            # Filled up entire batch, yield it.
            if next_spot == batch_size:
                yield paths, images

                # Overwrite the previous data.
                next_spot = 0

        # Last batch not filled, yield what remains.
        if next_spot != 0:
            yield paths[:next_spot], images[:next_spot]


class SaliencyDataGenerator:
    def __init__(self, image_dir, labels_path, batch_size=32,
            shape=(224, 224, 3), preprocess=None, shuffle=True):
        self.image_dir = image_dir
        self.labels_path = labels_path
        self.batch_size = batch_size
        self.shape = shape
        self.preprocess = preprocess
        self.shuffle = shuffle

        # Holds tuples of (path, label).
        self.data = list()

        with open(self.labels_path, 'r') as data:
            for line in data:
                path, label = line.split(' ')

                path = os.path.join(self.image_dir, path)
                label = int(float(label))

                # Add the training pair.
                self.data.append((path, label))

        self.nb_data = len(self.data)


    def generate(self):
        x = np.zeros((self.batch_size,) + self.shape, dtype=K.floatx())
        y = np.zeros((self.batch_size, 2), dtype=K.floatx())

        next_spot = 0

        while True:
            for i in range(self.batch_size):
                if next_spot == 0 and self.shuffle:
                    np.random.shuffle(self.data)

                image_path, label = self.data[next_spot]

                img = image.load_img(image_path, target_size=self.shape)
                img = image.img_to_array(img)

                if self.preprocess:
                    img = self.preprocess(img)

                x[i] = img

                # One hot encoding.
                y[i][0] = 0.0
                y[i][1] = 0.0
                y[i][label] = 1.0

                next_spot = (next_spot + 1) % self.nb_data

            yield x, y



if __name__ == "__main__":
    # Sample usage.
    grouped_datagen = GroupedDatagen(VALID_DIR)

    # Loops indefinitely.
    for examples, labels in grouped_datagen.generate():
        pass

    # Sample usage.
    filename_datagen = FilenameImageDatagen(VALID_DIR)

    # Loops until directory is exhausted.
    for filename, image in filename_datagen.generate():
        pass
